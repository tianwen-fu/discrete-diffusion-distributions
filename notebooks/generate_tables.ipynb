{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "DATA_SRC = os.path.realpath('../results/230425-160729')\n",
    "print(DATA_SRC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_file = os.path.join(DATA_SRC, 'OVER_PEAKINESS', 'metrics.pkl')\n",
    "with open(metric_file, 'rb') as f:\n",
    "    metrics = pickle.load(f)\n",
    "metrics.keys(), metrics['OVER_PEAKINESS/uniform_tau_0.01_M_1'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for M in ('1', '5'):\n",
    "    for tau in ('0.01', '0.1'):\n",
    "        for trans in ('Uniform', 'Gaussian', 'Absorbing', 'Random'):\n",
    "            if trans == 'Uniform': \n",
    "                print(rf'\\multirow{{4}}{{*}}{{$M={M}, \\tau={tau}$}}', end=' & ')\n",
    "            else:\n",
    "                print(rf' ', end=' & ')\n",
    "            print(trans, end=' & ')\n",
    "            exp_name = 'double_stochastic' if trans == 'Random' else trans.lower()\n",
    "            exp_name = f'OVER_PEAKINESS/{exp_name}_tau_{tau}_M_{M}'\n",
    "            assert exp_name in metrics\n",
    "            this_metric = metrics[exp_name]\n",
    "            print(f'{this_metric[\"ce_loss\"]:.3f}', f'{this_metric[\"kl_dataset_samples\"]:.3f}', f'{this_metric[\"kl_samples_dataset\"]:.3f}', sep=' & ', end='\\\\\\\\\\n')\n",
    "        print(r'\\midrule')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_file1 = os.path.join(DATA_SRC, 'ABSORBING_CENTER_M1', 'metrics.pkl')\n",
    "with open(metric_file1, 'rb') as f:\n",
    "    metrics1 = pickle.load(f)\n",
    "metric_file2 = os.path.join(DATA_SRC, 'ABSORBING_CENTER_M5', 'metrics.pkl')\n",
    "with open(metric_file2, 'rb') as f:\n",
    "    metrics2 = pickle.load(f)\n",
    "metrics = metrics1 | metrics2\n",
    "print(metrics.keys(), metrics[tuple(metrics.keys())[0]].keys(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for M in ('1', '5'):\n",
    "    for N in ('50', '100'):\n",
    "        for alignment in ('aligned', 'misaligned'):\n",
    "            if alignment == 'aligned': \n",
    "                print(rf'\\multirow{{2}}{{*}}{{$M={M}, N={N}$}}', end=' & ')\n",
    "            else:\n",
    "                print(rf' ', end=' & ')\n",
    "            print(alignment.capitalize(), end=' & ')\n",
    "            exp_name = f'ABSORBING_CENTER_M{M}/N{N}_M{M}_{alignment}'\n",
    "            assert exp_name in metrics\n",
    "            this_metric = metrics[exp_name]\n",
    "            print(f'{this_metric[\"ce_loss\"]:.3f}', f'{this_metric[\"kl_dataset_samples\"]:.3f}', f'{this_metric[\"kl_samples_dataset\"]:.3f}', sep=' & ', end='\\\\\\\\\\n')\n",
    "        print(r'\\midrule')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SRC = os.path.realpath('../results/230428-201104')\n",
    "\n",
    "metric_file = os.path.join(DATA_SRC, 'BETA_SCHEDULES', 'metrics.pkl')\n",
    "with open(metric_file, 'rb') as f:\n",
    "    metrics = pickle.load(f)\n",
    "metrics.keys(), metrics['BETA_SCHEDULES/gaussian_linear_0.1'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for transition in ('gaussian', 'uniform'):\n",
    "    print(r'\\multirow{8}{*}{', transition.capitalize(), '}', sep='')\n",
    "    for schedule_type in ('step', 'linear'):\n",
    "        for beta_end in ('0.01', '0.1', '1.0'):\n",
    "            if schedule_type == 'linear':\n",
    "                schedule_name = f'Linear(0.02, {beta_end})'\n",
    "            elif schedule_type == 'step':\n",
    "                schedule_name = f'Step(0.02, {beta_end}, 5)'\n",
    "            print(' & ', schedule_name, end=' & ')\n",
    "            exp_name = f'BETA_SCHEDULES/{transition}_{schedule_type}_{beta_end}'\n",
    "            assert exp_name in metrics, exp_name\n",
    "            this_metric = metrics[exp_name]\n",
    "            print(f'{this_metric[\"ce_loss\"]:.3f}', f'{this_metric[\"kl_dataset_samples\"]:.3f}', f'{this_metric[\"kl_samples_dataset\"]:.3f}', sep=' & ', end='\\\\\\\\\\n')\n",
    "    for schedule_type in ('cosine', 'jsd'):\n",
    "        exp_name = f'BETA_SCHEDULES/{transition}_{schedule_type}'\n",
    "        assert exp_name in metrics, exp_name\n",
    "        this_metric = metrics[exp_name]\n",
    "        print(' & ', schedule_type.capitalize(), end=' & ')\n",
    "        print(f'{this_metric[\"ce_loss\"]:.3f}', f'{this_metric[\"kl_dataset_samples\"]:.3f}', f'{this_metric[\"kl_samples_dataset\"]:.3f}', sep=' & ', end='\\\\\\\\\\n')\n",
    "    print(r'\\midrule')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d3exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
